{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TLdetect\n",
    "\n",
    "An implementation of a convolutional neural network to detect the state of traffic lights in images. The states are red, green, yellow and no traffic light. Using the **tensorflow** framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import random\n",
    "import os\n",
    "import src.data_processing as data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITERATIONS = 100\n",
    "BATCH_SIZE = 32\n",
    "KERNEL_SIZE = (3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "\n",
    "Loading the images and labels and treating the dataset to fit better on our model. Note that the images won't be loaded right now, only their file names, in order to save memory and avoid bottlenecks and errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels loaded: 13063\n"
     ]
    }
   ],
   "source": [
    "# Loading the labels\n",
    "# At this moment, the conv net will only classify if an image has or not a traffic light.\n",
    "labels = data.load_labels()\n",
    "print(\"Number of labels loaded: %d\" % len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set of 13063 images split in 3 sets.\n",
      "\n",
      "Train: (9438,)\n",
      "Validation: (1665,)\n",
      "Test: (1960,)\n"
     ]
    }
   ],
   "source": [
    "# Loading the images. In reality, just their names\n",
    "images = labels['file']\n",
    "X_train, X_val, X_test = data.split_dataset(images)\n",
    "\n",
    "# Debug\n",
    "print(\"Data set of %d images split in 3 sets.\\n\" % len(images))\n",
    "print(\"Train: {}\".format(X_train.shape))\n",
    "print(\"Validation: {}\".format(X_val.shape))\n",
    "print(\"Test: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lables extracted.\n",
      "\n",
      "Train labels shape: (9438,)\n",
      "Train validation shape: (1665,)\n",
      "Train test shape: (1960,)\n"
     ]
    }
   ],
   "source": [
    "# Spliting the labels\n",
    "y_train = data.extract_labels(labels, X_train)\n",
    "y_val = data.extract_labels(labels, X_val)\n",
    "y_test = data.extract_labels(labels, X_test)\n",
    "\n",
    "# Debug\n",
    "print(\"Lables extracted.\\n\")\n",
    "print(\"Train labels shape: {}\".format(y_train.shape))\n",
    "print(\"Train validation shape: {}\".format(y_val.shape))\n",
    "print(\"Train test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model\n",
    "\n",
    "At the following cells we will define our model. Our model, at this moment, will just classify if a given image has a traffic light or not.\n",
    "\n",
    "Note that the inputs pass through two max-pooling layers before starts to be recognized. This technique is used to reduce the dimensionality of the inputs.\n",
    "\n",
    "The original inputs has the dimension of (1200, 1920, 3).\n",
    "\n",
    "#### The following architecture will be used:\n",
    "1. **Pooling layer**\n",
    "+ **Pooling layer**\n",
    "+ **Pooling layer**\n",
    "+ **Convolutional layer w/ 64 filters**\n",
    "+ **Convolutional layer w/ 32 filters**\n",
    "+ **Pooling layer**\n",
    "+ **Convolutional layer w/ 32 filter**\n",
    "+ **Convolutional layer w/ 32 filter**\n",
    "+ **Convolutional layer w/ 16 filter**\n",
    "+ **Pooling layer**\n",
    "+ **512 Fully connected units with Dropout**\n",
    "+ **10 Fully connected units**\n",
    "+ **Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "max_pooling2d_1 (MaxPooling2 (None, 600, 960, 3)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 300, 480, 3)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 150, 240, 3)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 75, 120, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 120, 64)       1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 75, 120, 32)       18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 37, 60, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 37, 60, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 37, 60, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 37, 60, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 18, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8640)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               4424192   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 4,472,720\n",
      "Trainable params: 4,472,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.keras import layers, models, backend, optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.MaxPool2D(pool_size=2, strides=2,\n",
    "                           data_format='channels_last',\n",
    "                           input_shape=(1200, 1920, 3)\n",
    "                          ))\n",
    "model.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "model.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "model.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=KERNEL_SIZE, strides=1,\n",
    "                        padding='same',\n",
    "                        activation='relu'\n",
    "                       ))\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=KERNEL_SIZE, strides=1,\n",
    "                        padding='same',\n",
    "                        activation='relu'\n",
    "                       ))\n",
    "\n",
    "model.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=KERNEL_SIZE, strides=1,\n",
    "                        padding='same',\n",
    "                        activation='relu'\n",
    "                       ))\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=KERNEL_SIZE, strides=1,\n",
    "                        padding='same',\n",
    "                        activation='relu'\n",
    "                       ))\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=KERNEL_SIZE, strides=1,\n",
    "                        padding='same',\n",
    "                        activation='relu'\n",
    "                       ))\n",
    "model.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "optim = optimizers.SGD(1e-3, momentum=0.9)\n",
    "model.compile(optimizer=optim,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import callbacks\n",
    "filepath = 'models/tldetect_bin_classification_model'\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath, \n",
    "                                       monitor='loss',\n",
    "                                       verbose=1,\n",
    "                                       save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading a pre-trained model\n",
    "If exists. Must be placed on the 'models' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(os.path.exists(filepath)):\n",
    "   model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "293/294 [============================>.] - ETA: 0s - loss: 0.6516 - acc: 0.6246Epoch 00000: loss improved from 0.65549 to 0.65166, saving model to models/tldetect_bin_classification_model\n",
      "294/294 [==============================] - 249s - loss: 0.6517 - acc: 0.6241   \n",
      "Epoch 2/100\n",
      "293/294 [============================>.] - ETA: 0s - loss: 0.5713 - acc: 0.6869Epoch 00001: loss improved from 0.65166 to 0.57124, saving model to models/tldetect_bin_classification_model\n",
      "294/294 [==============================] - 246s - loss: 0.5712 - acc: 0.6872   \n",
      "Epoch 3/100\n",
      "293/294 [============================>.] - ETA: 0s - loss: 0.4744 - acc: 0.7811Epoch 00002: loss improved from 0.57124 to 0.47486, saving model to models/tldetect_bin_classification_model\n",
      "294/294 [==============================] - 243s - loss: 0.4749 - acc: 0.7809   \n",
      "Epoch 4/100\n",
      "293/294 [============================>.] - ETA: 0s - loss: 0.4090 - acc: 0.8173Epoch 00003: loss improved from 0.47486 to 0.40901, saving model to models/tldetect_bin_classification_model\n",
      "294/294 [==============================] - 244s - loss: 0.4090 - acc: 0.8173   \n",
      "Epoch 5/100\n",
      "293/294 [============================>.] - ETA: 0s - loss: 0.3602 - acc: 0.8383Epoch 00004: loss improved from 0.40901 to 0.36032, saving model to models/tldetect_bin_classification_model\n",
      "294/294 [==============================] - 242s - loss: 0.3603 - acc: 0.8383   \n",
      "Epoch 6/100\n",
      "293/294 [============================>.] - ETA: 0s - loss: 0.3188 - acc: 0.8613Epoch 00005: loss improved from 0.36032 to 0.31911, saving model to models/tldetect_bin_classification_model\n",
      "294/294 [==============================] - 241s - loss: 0.3191 - acc: 0.8613   \n",
      "Epoch 7/100\n",
      "293/294 [============================>.] - ETA: 0s - loss: 0.2700 - acc: 0.8867Epoch 00006: loss improved from 0.31911 to 0.27018, saving model to models/tldetect_bin_classification_model\n",
      "294/294 [==============================] - 243s - loss: 0.2702 - acc: 0.8866   \n",
      "Epoch 8/100\n"
     ]
    }
   ],
   "source": [
    "report = model.fit_generator(data.images_generator(X_train, y_train, BATCH_SIZE),\n",
    "                    int(X_train.shape[0]/BATCH_SIZE),\n",
    "                    epochs=NUM_ITERATIONS,\n",
    "                    callbacks=[checkpoint]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the training report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5d8b89bfa29b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'report' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(report.history['loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(report.history['acc'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
