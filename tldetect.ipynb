{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TLdetect\n",
    "\n",
    "An implementation of a convolutional neural network to detect the state of traffic lights in images. The states are red, green, yellow and no traffic light. Using the **tensorflow** framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import src.data_processing as data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_ITERATIONS = 100\n",
    "BATCH_SIZE = 64\n",
    "KERNEL_SIZE = (3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "\n",
    "Loading the images and labels and treating the dataset to fit better on our model. Note that the images won't be loaded right now, only their file names, in order to save memory and avoid bottlenecks and errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the labels\n",
    "# At this moment, the conv net will only classify if an image has or not a traffic light.\n",
    "labels = data.load_labels()\n",
    "print(\"Number of labels loaded: %d\" % len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the images. In reality, just their names\n",
    "images = labels['file']\n",
    "X_train, X_val, X_test = data.split_dataset(images)\n",
    "\n",
    "# Debug\n",
    "print(\"Data set of %d images split in 3 sets.\\n\" % len(images))\n",
    "print(\"Train: {}\".format(X_train.shape))\n",
    "print(\"Validation: {}\".format(X_val.shape))\n",
    "print(\"Test: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the labels\n",
    "y_train = data.extract_labels(labels, X_train)\n",
    "y_val = data.extract_labels(labels, X_val)\n",
    "y_test = data.extract_labels(labels, X_test)\n",
    "\n",
    "# Debug\n",
    "print(\"Lables extracted.\\n\")\n",
    "print(\"Train labels shape: {}\".format(y_train.shape))\n",
    "print(\"Train validation shape: {}\".format(y_val.shape))\n",
    "print(\"Train test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model\n",
    "\n",
    "At the following cells we will define our model. Our model, at this moment, will just classify if a given image has a traffic light or not.\n",
    "\n",
    "Note that the inputs pass through two max-pooling layers before starts to be recognized. This technique is used to reduce the dimensionality of the inputs.\n",
    "\n",
    "The original inputs has the dimension of (1200, 1920, 3).\n",
    "\n",
    "#### The following architecture will be used:\n",
    "1. **Pooling layer**\n",
    "+ **Pooling layer** (Output dimension will be (300, 480, 3))\n",
    "+ **Convolutional layer**\n",
    "+ **Pooling layer**\n",
    "+ **Convolutional layer**\n",
    "+ **Pooling layer**\n",
    "+ **Affine layer**\n",
    "+ **Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.MaxPool2D(pool_size=2, strides=2,\n",
    "                           data_format='channels_last',\n",
    "                           input_shape=(1200, 1920, 3)\n",
    "                          ))\n",
    "model.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "model.add(layers.Conv2D(filters=5, kernel_size=KERNEL_SIZE, strides=1,\n",
    "                        padding='same',\n",
    "                        activation='relu'\n",
    "                       ))\n",
    "model.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "model.add(layers.Conv2D(filters=4, kernel_size=KERNEL_SIZE, strides=1,\n",
    "                        padding='same',\n",
    "                        activation='relu'\n",
    "                       ))\n",
    "model.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "report = {}\n",
    "for it in range(NUM_ITERATIONS):\n",
    "    # Load a batch from disk\n",
    "    images = []\n",
    "    actual_labels = []\n",
    "    indexes = random.sample(range(len(X_train)), BATCH_SIZE)\n",
    "    for i in indexes:\n",
    "        images.append(np.array(Image.open('data/object-dataset/' + X_train[i])))\n",
    "        if (y_train[i] == 'trafficLight'):\n",
    "            actual_labels.append(np.array([0, 1]))\n",
    "        else:\n",
    "            actual_labels.append(np.array([1, 0]))\n",
    "\n",
    "    images = np.array(images)\n",
    "    actual_labels = np.array(actual_labels)\n",
    "    \n",
    "    # Training the model\n",
    "    train_info = model.train_on_batch(images, actual_labels)\n",
    "    \n",
    "    # Report\n",
    "    report[it] = train_info\n",
    "    if not it % 5:\n",
    "        print('-' * 60)\n",
    "        print('Iteration {}'.format(it))\n",
    "        print('Loss: {}, Accuracy: {}'.format(train_info[0], train_info[1]))\n",
    "        \n",
    "print('-' * 60)\n",
    "print('Train ended. Final metrics after {} iterations:'.format(NUM_ITERATIONS))\n",
    "print('Loss: {}, Accuracy: {}'.format(train_info[0], train_info[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
