{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TLdetect\n",
    "\n",
    "An implementation of a convolutional neural network to detect the state of traffic lights in images. The states are red, green, yellow and no traffic light. Using the **tensorflow** framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import src.data_processing as data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "\n",
    "Loading the images and labels and treating the dataset to fit better on our model. Note that the images won't be loaded right now, only their file names, in order to save memory and avoid bottlenecks and errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the labels\n",
    "# At this moment, the conv net will only classify if an image has or not a traffic light.\n",
    "labels = data.load_labels()\n",
    "print(\"Number of labels loaded: %d\" % len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the images. In reality, just their names\n",
    "images = labels['file']\n",
    "X_train, X_val, X_test = data.split_dataset(images)\n",
    "\n",
    "# Debug\n",
    "print(\"Data set of %d images split in 3 sets.\\n\" % len(images))\n",
    "print(\"Train: {}\".format(X_train.shape))\n",
    "print(\"Validation: {}\".format(X_val.shape))\n",
    "print(\"Test: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the labels\n",
    "y_train = data.extract_labels(labels, X_train)\n",
    "y_val = data.extract_labels(labels, X_val)\n",
    "y_test = data.extract_labels(labels, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model\n",
    "\n",
    "At the following cells we will define our model. Our model, at this moment, will just classify if a given image has a traffic light or not.\n",
    "\n",
    "#### The following architecture will be used:\n",
    "1. **Convolutional layer**\n",
    "+ **Pooling layer**\n",
    "+ **Convolutional layer**\n",
    "+ **Pooling layer**\n",
    "+ **Affine layer**\n",
    "+ **Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining useful functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=5, kernel_size=3, strides=1,\n",
    "                        padding='same',\n",
    "                        data_format='channels_last',\n",
    "                        input_shape=(1920, 1200, 3),\n",
    "                        activation='relu'\n",
    "                       ))\n",
    "model.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "model.add(layers.Conv2D(filters=4, kernel_size=3, strides=1,\n",
    "                        padding='same',\n",
    "                        activation='relu'\n",
    "                       ))\n",
    "model.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dense(2))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X_train[0]\n",
    "print(test)\n",
    "#img = np.array('')\n",
    "#for i in range(2):\n",
    "img = np.array(Image.open('data/object-dataset/' + test))\n",
    "img = img.reshape((1, 1920, 1200, 3))\n",
    "\n",
    "print(img.shape)\n",
    "#label_y = ['car']\n",
    "#model.fit(img, label_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolution(inputs, W, stride=(1, 1, 1, 1), padding='SAME'):\n",
    "    \"\"\"\n",
    "        Given inputs and weights, applies a convolution to the images.\n",
    "        Note:\n",
    "            inputs has the shape (N, H, W, C)\n",
    "            and weights has the shape (H, W, C, K)\n",
    "            where:\n",
    "            N = Number of inputs\n",
    "            H = Height\n",
    "            W = Width\n",
    "            C = Channel\n",
    "            K = Number of kernels\n",
    "    \"\"\"\n",
    "    return tf.nn.conv2d(inputs, W, strides=stride, padding=padding)\n",
    "\n",
    "def max_pooling(inputs, window_size=(1, 2, 2, 1), stride=(1, 2, 2, 1),\n",
    "                padding='SAME'):\n",
    "    \"\"\"\n",
    "        Applies a 2x2 max-pooling in a given image. Reduces the resolution.\n",
    "    \"\"\"\n",
    "    return tf.nn.max_pool(inputs, ksize=window_size, strides=stride,\n",
    "                          padding=padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining hyperparameters, weights and biases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Improve the implementation. The model is fitted only for one type. Generalize more.\n",
    "\n",
    "# Defining inputs\n",
    "X = tf.placeholder(tf.float32, shape=[None, 1200, 1920, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "# Parameters\n",
    "conv_0_params = {}\n",
    "conv_1_params = {}\n",
    "fc_0_params = {}\n",
    "fc_1_params = {}\n",
    "conv_0_params['W'] = tf.Variable(tf.random_normal((3, 3, 3, 4), mean=0, stddev=1e-2),\n",
    "                        dtype=tf.float32)\n",
    "conv_0_params['b'] = tf.Variable(tf.zeros(4))\n",
    "\n",
    "conv_1_params['W'] = tf.Variable(tf.random_normal((3, 3, 4, 4), mean=0, stddev=1e-2),\n",
    "                        dtype=tf.float32)\n",
    "conv_1_params['b'] = tf.Variable(tf.zeros(4))\n",
    "\n",
    "fc_0_params['W'] = tf.Variable(tf.random_normal((300*480*4, 100), mean=0, stddev=1e-2),\n",
    "                        dtype=tf.float32)\n",
    "fc_0_params['b'] = tf.Variable(tf.zeros(100))\n",
    "\n",
    "fc_1_params['W'] = tf.Variable(tf.random_normal((100, 2), mean=0, stddev=1e-2),\n",
    "                        dtype=tf.float32)\n",
    "fc_1_params['b'] = tf.Variable(tf.zeros(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the architecture itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the architecture\n",
    "conv_0 = tf.nn.relu(convolution(X, conv_0_params['W']) + conv_0_params['b'])\n",
    "pool_0 = max_pooling(conv_0)\n",
    "conv_1 = tf.nn.relu(convolution(pool_0, conv_1_params['W']) + conv_1_params['b'])\n",
    "pool_1 = max_pooling(conv_1)\n",
    "\n",
    "reshaped_X = tf.reshape(pool_1, [-1, 300 * 480 * 4])\n",
    "fc_layer_0 = tf.nn.relu(tf.matmul(reshaped_X, fc_0_params['W']) + fc_0_params['b'])\n",
    "fc_layer_1 = tf.matmul(fc_layer_0, fc_1_params['W']) + fc_1_params['b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selecting the data to be used for training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: Change the inputs to arrays or lists to load effectively them at this cell.\n",
    "\n",
    "Images = []\n",
    "Image.open('data/object-dataset/' + X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_grow\n",
    "sess = tf.Session()\n",
    "\n",
    "# Defining the loss function\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=fc_layer_1))\n",
    "\n",
    "training_step = tf.train.RMSPropOptimizer(1e-4).minimize(loss)\n",
    "prediction_test = tf.equal(tf.argmax(fc_layer_1,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction_test, tf.float32))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Accuracy not being measured as should be.\n",
    "#       Beyond that, put everything in half-precision to save memory\n",
    "\n",
    "# Effectively training\n",
    "with sess.as_default():\n",
    "    for iteration in range(100):\n",
    "        if not (iteration % 10):\n",
    "            loss_value = loss.eval(feed_dict={Y:Y_train[:2], X:Images})\n",
    "            print(\"Loss: %f\" % loss_value)\n",
    "        if not (iteration % 50):\n",
    "            acc = accuracy.eval(feed_dict={Y:Y_train[:2], X:Images})\n",
    "            print(\"Iteration: %d, Accuracy: %f\" % (iteration, acc))\n",
    "        training_step.run(feed_dict={Y:Y_train[:2], X:Images})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(Images[0])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
