{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TLdetect\n",
    "\n",
    "An implementation of a convolutional neural network to detect the state of traffic lights in images. The states are red, green, yellow and no traffic light. Using the **tensorflow** framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import random\n",
    "import os\n",
    "import src.data_processing as data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITERATIONS = 10\n",
    "BATCH_SIZE = 32\n",
    "KERNEL_SIZE = (3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "\n",
    "Loading the images and labels and treating the dataset to fit better on our model. Note that the images won't be loaded right now, only their file names, in order to save memory and avoid bottlenecks and errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels loaded: 13063\n"
     ]
    }
   ],
   "source": [
    "# Loading the labels\n",
    "# At this moment, the conv net will only classify if an image has or not a traffic light.\n",
    "labels = data.load_labels()\n",
    "print(\"Number of labels loaded: %d\" % len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set of 13063 images split in 3 sets.\n",
      "\n",
      "Train: (9438,)\n",
      "Validation: (1665,)\n",
      "Test: (1960,)\n"
     ]
    }
   ],
   "source": [
    "# Loading the images. In reality, just their names\n",
    "images = labels['file']\n",
    "X_train, X_val, X_test = data.split_dataset(images)\n",
    "\n",
    "# Debug\n",
    "print(\"Data set of %d images split in 3 sets.\\n\" % len(images))\n",
    "print(\"Train: {}\".format(X_train.shape))\n",
    "print(\"Validation: {}\".format(X_val.shape))\n",
    "print(\"Test: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lables extracted.\n",
      "\n",
      "Train labels shape: (9438,)\n",
      "Train validation shape: (1665,)\n",
      "Train test shape: (1960,)\n"
     ]
    }
   ],
   "source": [
    "# Spliting the labels\n",
    "y_train = data.extract_tl_labels(labels, X_train)\n",
    "y_val = data.extract_tl_labels(labels, X_val)\n",
    "y_test = data.extract_tl_labels(labels, X_test)\n",
    "\n",
    "# Debug\n",
    "print(\"Lables extracted.\\n\")\n",
    "print(\"Train labels shape: {}\".format(y_train.shape))\n",
    "print(\"Train validation shape: {}\".format(y_val.shape))\n",
    "print(\"Train test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model\n",
    "\n",
    "At the following cells we will define our model. Our model, at this moment, will just classify if a given image has a traffic light or not.\n",
    "\n",
    "Note that the inputs pass through two max-pooling layers before starts to be recognized. This technique is used to reduce the dimensionality of the inputs.\n",
    "\n",
    "The original inputs has the dimension of (1200, 1920, 3).\n",
    "\n",
    "#### The following architecture will be used:\n",
    "1. **Pooling layer**\n",
    "+ **Pooling layer**\n",
    "+ **Pooling layer**\n",
    "+ **Convolutional layer w/ 64 filters**\n",
    "+ **Convolutional layer w/ 32 filters**\n",
    "+ **Pooling layer**\n",
    "+ **Convolutional layer w/ 32 filter**\n",
    "+ **Convolutional layer w/ 32 filter**\n",
    "+ **Convolutional layer w/ 16 filter**\n",
    "+ **Pooling layer**\n",
    "+ **512 Fully connected units with Dropout**\n",
    "+ **64 Fully connected units**\n",
    "+ **Classification - 7 classes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "max_pooling2d_1 (MaxPooling2 (None, 600, 960, 3)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 300, 480, 3)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 150, 240, 3)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 75, 120, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 120, 64)       1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 75, 120, 32)       18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 37, 60, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 37, 60, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 37, 60, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 37, 60, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 18, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8640)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               4424192   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 4,500,855\n",
      "Trainable params: 4,500,855\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.keras import layers, models, backend, optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.MaxPool2D(pool_size=2, strides=2,\n",
    "                           data_format='channels_last',\n",
    "                           input_shape=(1200, 1920, 3)\n",
    "                          ))\n",
    "model.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "model.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "model.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=KERNEL_SIZE, strides=1,\n",
    "                        padding='same',\n",
    "                        activation='relu'\n",
    "                       ))\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=KERNEL_SIZE, strides=1,\n",
    "                        padding='same',\n",
    "                        activation='relu'\n",
    "                       ))\n",
    "\n",
    "model.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=KERNEL_SIZE, strides=1,\n",
    "                        padding='same',\n",
    "                        activation='relu'\n",
    "                       ))\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=KERNEL_SIZE, strides=1,\n",
    "                        padding='same',\n",
    "                        activation='relu'\n",
    "                       ))\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=KERNEL_SIZE, strides=1,\n",
    "                        padding='same',\n",
    "                        activation='relu'\n",
    "                       ))\n",
    "model.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "optim = optimizers.RMSprop()\n",
    "model.compile(optimizer=optim,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import callbacks\n",
    "filepath = 'models/tldetect_tl_classification_model'\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath, \n",
    "                                       monitor='loss',\n",
    "                                       verbose=1,\n",
    "                                       save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading a pre-trained model\n",
    "If exists. Must be placed on the 'models' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(os.path.exists(filepath)):\n",
    "   model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "293/294 [============================>.] - ETA: 0s - loss: 4.7481 - acc: 0.7054Epoch 00000: loss improved from inf to 4.74394, saving model to models/tldetect_tl_classification_model\n",
      "294/294 [==============================] - 236s - loss: 4.7439 - acc: 0.7057   \n",
      "Epoch 2/10\n",
      "293/294 [============================>.] - ETA: 0s - loss: 4.7481 - acc: 0.7054Epoch 00001: loss did not improve\n",
      "294/294 [==============================] - 238s - loss: 4.7439 - acc: 0.7057   \n",
      "Epoch 3/10\n",
      " 45/294 [===>..........................] - ETA: 219s - loss: 4.6451 - acc: 0.7118"
     ]
    }
   ],
   "source": [
    "report = model.fit_generator(data.images_tl_generator(X_train, y_train, BATCH_SIZE),\n",
    "                    int(X_train.shape[0]/BATCH_SIZE),\n",
    "                    epochs=NUM_ITERATIONS,\n",
    "                    callbacks=[checkpoint]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the training report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(report.history['loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(report.history['acc'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### Testing on the validation data ###\")\n",
    "for (x, y) in data.images_tl_generator(X_val, y_val, BATCH_SIZE):\n",
    "    log = model.test_on_batch(x, y)\n",
    "    print(\"Loss: {:.4f}, Accuracy: {:.2f}%\".format(float(log[0]), log[1] * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
